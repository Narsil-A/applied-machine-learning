---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
Cell In [13], line 26
     22     return y_scores_array
     24     raise NotImplementedError()
---> 26 answer_six()

Cell In [13], line 11, in answer_six()
      7 clf = LogisticRegression()
      9 grid_clf_acc = GridSearchCV(clf, grid_values, scoring = 'recall')
---> 11 grid_clf_acc.fit(X_train, y_train)
     13 y_scores = grid_clf_acc.cv_results_['mean_test_score']
     15 #print(y_scores)
     16 #print(len(y_scores))

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875, in BaseSearchCV.fit(self, X, y, groups, **fit_params)
    869     results = self._format_results(
    870         all_candidate_params, n_splits, all_out, all_more_results
    871     )
    873     return results
--> 875 self._run_search(evaluate_candidates)
    877 # multimetric is determined here because in the case of a callable
    878 # self.scoring the return type is only known after calling
    879 first_test_score = all_out[0]["test_scores"]

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379, in GridSearchCV._run_search(self, evaluate_candidates)
   1377 def _run_search(self, evaluate_candidates):
   1378     """Search all candidates in param_grid"""
-> 1379     evaluate_candidates(ParameterGrid(self.param_grid))

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822, in BaseSearchCV.fit.<locals>.evaluate_candidates(candidate_params, cv, more_results)
    814 if self.verbose > 0:
    815     print(
    816         "Fitting {0} folds for each of {1} candidates,"
    817         " totalling {2} fits".format(
    818             n_splits, n_candidates, n_candidates * n_splits
    819         )
    820     )
--> 822 out = parallel(
    823     delayed(_fit_and_score)(
    824         clone(base_estimator),
    825         X,
    826         y,
    827         train=train,
    828         test=test,
    829         parameters=parameters,
    830         split_progress=(split_idx, n_splits),
    831         candidate_progress=(cand_idx, n_candidates),
    832         **fit_and_score_kwargs,
    833     )
    834     for (cand_idx, parameters), (split_idx, (train, test)) in product(
    835         enumerate(candidate_params), enumerate(cv.split(X, y, groups))
    836     )
    837 )
    839 if len(out) < 1:
    840     raise ValueError(
    841         "No fits were performed. "
    842         "Was the CV iterator empty? "
    843         "Were there no candidates?"
    844     )

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1088, in Parallel.__call__(self, iterable)
   1085 if self.dispatch_one_batch(iterator):
   1086     self._iterating = self._original_iterator is not None
-> 1088 while self.dispatch_one_batch(iterator):
   1089     pass
   1091 if pre_dispatch == "all" or n_jobs == 1:
   1092     # The iterable was consumed all at once by the above for loop.
   1093     # No need to wait for async callbacks to trigger to
   1094     # consumption.

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator)
    899     return False
    900 else:
--> 901     self._dispatch(tasks)
    902     return True

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch)
    817 with self._lock:
    818     job_idx = len(self._jobs)
--> 819     job = self._backend.apply_async(batch, callback=cb)
    820     # A job can complete so quickly than its callback is
    821     # called before we get here, causing self._jobs to
    822     # grow. To ensure correct results ordering, .insert is
    823     # used (rather than .append) in the following line
    824     self._jobs.insert(job_idx, job)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:208, in SequentialBackend.apply_async(self, func, callback)
    206 def apply_async(self, func, callback=None):
    207     """Schedule a func to be run"""
--> 208     result = ImmediateResult(func)
    209     if callback:
    210         callback(result)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:597, in ImmediateResult.__init__(self, batch)
    594 def __init__(self, batch):
    595     # Don't delay the application, to avoid keeping the input
    596     # arguments in memory
--> 597     self.results = batch()

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in BatchedCalls.__call__(self)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in <listcomp>(.0)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py:117, in _FuncWrapper.__call__(self, *args, **kwargs)
    115 def __call__(self, *args, **kwargs):
    116     with config_context(**self.config):
--> 117         return self.function(*args, **kwargs)

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686, in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)
    684         estimator.fit(X_train, **fit_params)
    685     else:
--> 686         estimator.fit(X_train, y_train, **fit_params)
    688 except Exception:
    689     # Note fit time as time until error
    690     fit_time = time.time() - start_time

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1233, in LogisticRegression.fit(self, X, y, sample_weight)
   1230 else:
   1231     n_threads = 1
-> 1233 fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(
   1234     path_func(
   1235         X,
   1236         y,
   1237         pos_class=class_,
   1238         Cs=[C_],
   1239         l1_ratio=self.l1_ratio,
   1240         fit_intercept=self.fit_intercept,
   1241         tol=self.tol,
   1242         verbose=self.verbose,
   1243         solver=solver,
   1244         multi_class=multi_class,
   1245         max_iter=self.max_iter,
   1246         class_weight=self.class_weight,
   1247         check_input=False,
   1248         random_state=self.random_state,
   1249         coef=warm_start_coef_,
   1250         penalty=penalty,
   1251         max_squared_sum=max_squared_sum,
   1252         sample_weight=sample_weight,
   1253         n_threads=n_threads,
   1254     )
   1255     for class_, warm_start_coef_ in zip(classes_, warm_start_coef)
   1256 )
   1258 fold_coefs_, _, n_iter_ = zip(*fold_coefs_)
   1259 self.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, 0]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1085, in Parallel.__call__(self, iterable)
   1076 try:
   1077     # Only set self._iterating to True if at least a batch
   1078     # was dispatched. In particular this covers the edge
   (...)
   1082     # was very quick and its callback already dispatched all the
   1083     # remaining jobs.
   1084     self._iterating = False
-> 1085     if self.dispatch_one_batch(iterator):
   1086         self._iterating = self._original_iterator is not None
   1088     while self.dispatch_one_batch(iterator):

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator)
    899     return False
    900 else:
--> 901     self._dispatch(tasks)
    902     return True

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch)
    817 with self._lock:
    818     job_idx = len(self._jobs)
--> 819     job = self._backend.apply_async(batch, callback=cb)
    820     # A job can complete so quickly than its callback is
    821     # called before we get here, causing self._jobs to
    822     # grow. To ensure correct results ordering, .insert is
    823     # used (rather than .append) in the following line
    824     self._jobs.insert(job_idx, job)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:208, in SequentialBackend.apply_async(self, func, callback)
    206 def apply_async(self, func, callback=None):
    207     """Schedule a func to be run"""
--> 208     result = ImmediateResult(func)
    209     if callback:
    210         callback(result)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:597, in ImmediateResult.__init__(self, batch)
    594 def __init__(self, batch):
    595     # Don't delay the application, to avoid keeping the input
    596     # arguments in memory
--> 597     self.results = batch()

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in BatchedCalls.__call__(self)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in <listcomp>(.0)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py:117, in _FuncWrapper.__call__(self, *args, **kwargs)
    115 def __call__(self, *args, **kwargs):
    116     with config_context(**self.config):
--> 117         return self.function(*args, **kwargs)

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:436, in _logistic_regression_path(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)
    432 l2_reg_strength = 1.0 / C
    433 iprint = [-1, 50, 1, 100, 101][
    434     np.searchsorted(np.array([0, 1, 2, 3]), verbose)
    435 ]
--> 436 opt_res = optimize.minimize(
    437     func,
    438     w0,
    439     method="L-BFGS-B",
    440     jac=True,
    441     args=(X, target, sample_weight, l2_reg_strength, n_threads),
    442     options={"iprint": iprint, "gtol": tol, "maxiter": max_iter},
    443 )
    444 n_iter_i = _check_optimize_result(
    445     solver,
    446     opt_res,
    447     max_iter,
    448     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
    449 )
    450 w0, loss = opt_res.x, opt_res.fun

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_minimize.py:681, in minimize(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)
    678     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,
    679                              **options)
    680 elif meth == 'l-bfgs-b':
--> 681     res = _minimize_lbfgsb(fun, x0, args, jac, bounds,
    682                            callback=callback, **options)
    683 elif meth == 'tnc':
    684     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,
    685                         **options)

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:362, in _minimize_lbfgsb(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)
    356 task_str = task.tobytes()
    357 if task_str.startswith(b'FG'):
    358     # The minimization routine wants f and g at the current x.
    359     # Note that interruptions due to maxfun are postponed
    360     # until the completion of the current minimization iteration.
    361     # Overwrite f and g:
--> 362     f, g = func_and_grad(x)
    363 elif task_str.startswith(b'NEW_X'):
    364     # new iteration
    365     n_iterations += 1

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285, in ScalarFunction.fun_and_grad(self, x)
    283 if not np.array_equal(x, self.x):
    284     self._update_x_impl(x)
--> 285 self._update_fun()
    286 self._update_grad()
    287 return self.f, self.g

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251, in ScalarFunction._update_fun(self)
    249 def _update_fun(self):
    250     if not self.f_updated:
--> 251         self._update_fun_impl()
    252         self.f_updated = True

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155, in ScalarFunction.__init__.<locals>.update_fun()
    154 def update_fun():
--> 155     self.f = fun_wrapped(self.x)

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137, in ScalarFunction.__init__.<locals>.fun_wrapped(x)
    133 self.nfev += 1
    134 # Send a copy because the user may overwrite it.
    135 # Overwriting results in undefined behaviour because
    136 # fun(self.x) will change self.x, with the two no longer linked.
--> 137 fx = fun(np.copy(x), *args)
    138 # Make sure the function returns a true scalar
    139 if not np.isscalar(fx):

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76, in MemoizeJac.__call__(self, x, *args)
     74 def __call__(self, x, *args):
     75     """ returns the the function value """
---> 76     self._compute_if_needed(x, *args)
     77     return self._value

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70, in MemoizeJac._compute_if_needed(self, x, *args)
     68 if not np.all(x == self.x) or self._value is None or self.jac is None:
     69     self.x = np.asarray(x).copy()
---> 70     fg = self.fun(x, *args)
     71     self.jac = fg[1]
     72     self._value = fg[0]

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:187, in LinearModelLoss.loss_gradient(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)
    185 n_features, n_classes = X.shape[1], self.base_loss.n_classes
    186 n_dof = n_features + int(self.fit_intercept)
--> 187 weights, intercept, raw_prediction = self._w_intercept_raw(coef, X)
    189 loss, grad_per_sample = self.base_loss.loss_gradient(
    190     y_true=y,
    191     raw_prediction=raw_prediction,
    192     sample_weight=sample_weight,
    193     n_threads=n_threads,
    194 )
    195 loss = loss.sum()

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:99, in LinearModelLoss._w_intercept_raw(self, coef, X)
     97         intercept = 0.0
     98         weights = coef
---> 99     raw_prediction = X @ weights + intercept
    100 else:
    101     # reshape to (n_classes, n_dof)
    102     if coef.ndim == 1:

KeyboardInterrupt: 






---------------------------------------------------------------------------
KeyboardInterrupt                         Traceback (most recent call last)
Cell In [15], line 10
      7     sns.heatmap(scores.reshape(5,2), xticklabels=['l1','l2'], yticklabels=[0.01, 0.1, 1, 10])
      8     plt.yticks(rotation=0);
---> 10 GridSearch_Heatmap(answer_six())

Cell In [13], line 11, in answer_six()
      7 clf = LogisticRegression()
      9 grid_clf_acc = GridSearchCV(clf, grid_values, scoring = 'recall')
---> 11 grid_clf_acc.fit(X_train, y_train)
     13 y_scores = grid_clf_acc.cv_results_['mean_test_score']
     15 #print(y_scores)
     16 #print(len(y_scores))

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875, in BaseSearchCV.fit(self, X, y, groups, **fit_params)
    869     results = self._format_results(
    870         all_candidate_params, n_splits, all_out, all_more_results
    871     )
    873     return results
--> 875 self._run_search(evaluate_candidates)
    877 # multimetric is determined here because in the case of a callable
    878 # self.scoring the return type is only known after calling
    879 first_test_score = all_out[0]["test_scores"]

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1379, in GridSearchCV._run_search(self, evaluate_candidates)
   1377 def _run_search(self, evaluate_candidates):
   1378     """Search all candidates in param_grid"""
-> 1379     evaluate_candidates(ParameterGrid(self.param_grid))

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822, in BaseSearchCV.fit.<locals>.evaluate_candidates(candidate_params, cv, more_results)
    814 if self.verbose > 0:
    815     print(
    816         "Fitting {0} folds for each of {1} candidates,"
    817         " totalling {2} fits".format(
    818             n_splits, n_candidates, n_candidates * n_splits
    819         )
    820     )
--> 822 out = parallel(
    823     delayed(_fit_and_score)(
    824         clone(base_estimator),
    825         X,
    826         y,
    827         train=train,
    828         test=test,
    829         parameters=parameters,
    830         split_progress=(split_idx, n_splits),
    831         candidate_progress=(cand_idx, n_candidates),
    832         **fit_and_score_kwargs,
    833     )
    834     for (cand_idx, parameters), (split_idx, (train, test)) in product(
    835         enumerate(candidate_params), enumerate(cv.split(X, y, groups))
    836     )
    837 )
    839 if len(out) < 1:
    840     raise ValueError(
    841         "No fits were performed. "
    842         "Was the CV iterator empty? "
    843         "Were there no candidates?"
    844     )

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1088, in Parallel.__call__(self, iterable)
   1085 if self.dispatch_one_batch(iterator):
   1086     self._iterating = self._original_iterator is not None
-> 1088 while self.dispatch_one_batch(iterator):
   1089     pass
   1091 if pre_dispatch == "all" or n_jobs == 1:
   1092     # The iterable was consumed all at once by the above for loop.
   1093     # No need to wait for async callbacks to trigger to
   1094     # consumption.

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator)
    899     return False
    900 else:
--> 901     self._dispatch(tasks)
    902     return True

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch)
    817 with self._lock:
    818     job_idx = len(self._jobs)
--> 819     job = self._backend.apply_async(batch, callback=cb)
    820     # A job can complete so quickly than its callback is
    821     # called before we get here, causing self._jobs to
    822     # grow. To ensure correct results ordering, .insert is
    823     # used (rather than .append) in the following line
    824     self._jobs.insert(job_idx, job)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:208, in SequentialBackend.apply_async(self, func, callback)
    206 def apply_async(self, func, callback=None):
    207     """Schedule a func to be run"""
--> 208     result = ImmediateResult(func)
    209     if callback:
    210         callback(result)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:597, in ImmediateResult.__init__(self, batch)
    594 def __init__(self, batch):
    595     # Don't delay the application, to avoid keeping the input
    596     # arguments in memory
--> 597     self.results = batch()

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in BatchedCalls.__call__(self)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in <listcomp>(.0)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py:117, in _FuncWrapper.__call__(self, *args, **kwargs)
    115 def __call__(self, *args, **kwargs):
    116     with config_context(**self.config):
--> 117         return self.function(*args, **kwargs)

File /opt/conda/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:686, in _fit_and_score(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)
    684         estimator.fit(X_train, **fit_params)
    685     else:
--> 686         estimator.fit(X_train, y_train, **fit_params)
    688 except Exception:
    689     # Note fit time as time until error
    690     fit_time = time.time() - start_time

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:1233, in LogisticRegression.fit(self, X, y, sample_weight)
   1230 else:
   1231     n_threads = 1
-> 1233 fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(
   1234     path_func(
   1235         X,
   1236         y,
   1237         pos_class=class_,
   1238         Cs=[C_],
   1239         l1_ratio=self.l1_ratio,
   1240         fit_intercept=self.fit_intercept,
   1241         tol=self.tol,
   1242         verbose=self.verbose,
   1243         solver=solver,
   1244         multi_class=multi_class,
   1245         max_iter=self.max_iter,
   1246         class_weight=self.class_weight,
   1247         check_input=False,
   1248         random_state=self.random_state,
   1249         coef=warm_start_coef_,
   1250         penalty=penalty,
   1251         max_squared_sum=max_squared_sum,
   1252         sample_weight=sample_weight,
   1253         n_threads=n_threads,
   1254     )
   1255     for class_, warm_start_coef_ in zip(classes_, warm_start_coef)
   1256 )
   1258 fold_coefs_, _, n_iter_ = zip(*fold_coefs_)
   1259 self.n_iter_ = np.asarray(n_iter_, dtype=np.int32)[:, 0]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:1085, in Parallel.__call__(self, iterable)
   1076 try:
   1077     # Only set self._iterating to True if at least a batch
   1078     # was dispatched. In particular this covers the edge
   (...)
   1082     # was very quick and its callback already dispatched all the
   1083     # remaining jobs.
   1084     self._iterating = False
-> 1085     if self.dispatch_one_batch(iterator):
   1086         self._iterating = self._original_iterator is not None
   1088     while self.dispatch_one_batch(iterator):

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:901, in Parallel.dispatch_one_batch(self, iterator)
    899     return False
    900 else:
--> 901     self._dispatch(tasks)
    902     return True

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:819, in Parallel._dispatch(self, batch)
    817 with self._lock:
    818     job_idx = len(self._jobs)
--> 819     job = self._backend.apply_async(batch, callback=cb)
    820     # A job can complete so quickly than its callback is
    821     # called before we get here, causing self._jobs to
    822     # grow. To ensure correct results ordering, .insert is
    823     # used (rather than .append) in the following line
    824     self._jobs.insert(job_idx, job)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:208, in SequentialBackend.apply_async(self, func, callback)
    206 def apply_async(self, func, callback=None):
    207     """Schedule a func to be run"""
--> 208     result = ImmediateResult(func)
    209     if callback:
    210         callback(result)

File /opt/conda/lib/python3.9/site-packages/joblib/_parallel_backends.py:597, in ImmediateResult.__init__(self, batch)
    594 def __init__(self, batch):
    595     # Don't delay the application, to avoid keeping the input
    596     # arguments in memory
--> 597     self.results = batch()

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in BatchedCalls.__call__(self)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/joblib/parallel.py:288, in <listcomp>(.0)
    284 def __call__(self):
    285     # Set the default nested backend to self._backend but do not set the
    286     # change the default number of processes to -1
    287     with parallel_backend(self._backend, n_jobs=self._n_jobs):
--> 288         return [func(*args, **kwargs)
    289                 for func, args, kwargs in self.items]

File /opt/conda/lib/python3.9/site-packages/sklearn/utils/fixes.py:117, in _FuncWrapper.__call__(self, *args, **kwargs)
    115 def __call__(self, *args, **kwargs):
    116     with config_context(**self.config):
--> 117         return self.function(*args, **kwargs)

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:436, in _logistic_regression_path(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)
    432 l2_reg_strength = 1.0 / C
    433 iprint = [-1, 50, 1, 100, 101][
    434     np.searchsorted(np.array([0, 1, 2, 3]), verbose)
    435 ]
--> 436 opt_res = optimize.minimize(
    437     func,
    438     w0,
    439     method="L-BFGS-B",
    440     jac=True,
    441     args=(X, target, sample_weight, l2_reg_strength, n_threads),
    442     options={"iprint": iprint, "gtol": tol, "maxiter": max_iter},
    443 )
    444 n_iter_i = _check_optimize_result(
    445     solver,
    446     opt_res,
    447     max_iter,
    448     extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,
    449 )
    450 w0, loss = opt_res.x, opt_res.fun

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_minimize.py:681, in minimize(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)
    678     res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,
    679                              **options)
    680 elif meth == 'l-bfgs-b':
--> 681     res = _minimize_lbfgsb(fun, x0, args, jac, bounds,
    682                            callback=callback, **options)
    683 elif meth == 'tnc':
    684     res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,
    685                         **options)

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_lbfgsb_py.py:362, in _minimize_lbfgsb(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)
    356 task_str = task.tobytes()
    357 if task_str.startswith(b'FG'):
    358     # The minimization routine wants f and g at the current x.
    359     # Note that interruptions due to maxfun are postponed
    360     # until the completion of the current minimization iteration.
    361     # Overwrite f and g:
--> 362     f, g = func_and_grad(x)
    363 elif task_str.startswith(b'NEW_X'):
    364     # new iteration
    365     n_iterations += 1

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:285, in ScalarFunction.fun_and_grad(self, x)
    283 if not np.array_equal(x, self.x):
    284     self._update_x_impl(x)
--> 285 self._update_fun()
    286 self._update_grad()
    287 return self.f, self.g

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:251, in ScalarFunction._update_fun(self)
    249 def _update_fun(self):
    250     if not self.f_updated:
--> 251         self._update_fun_impl()
    252         self.f_updated = True

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:155, in ScalarFunction.__init__.<locals>.update_fun()
    154 def update_fun():
--> 155     self.f = fun_wrapped(self.x)

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_differentiable_functions.py:137, in ScalarFunction.__init__.<locals>.fun_wrapped(x)
    133 self.nfev += 1
    134 # Send a copy because the user may overwrite it.
    135 # Overwriting results in undefined behaviour because
    136 # fun(self.x) will change self.x, with the two no longer linked.
--> 137 fx = fun(np.copy(x), *args)
    138 # Make sure the function returns a true scalar
    139 if not np.isscalar(fx):

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:76, in MemoizeJac.__call__(self, x, *args)
     74 def __call__(self, x, *args):
     75     """ returns the the function value """
---> 76     self._compute_if_needed(x, *args)
     77     return self._value

File /opt/conda/lib/python3.9/site-packages/scipy/optimize/_optimize.py:70, in MemoizeJac._compute_if_needed(self, x, *args)
     68 if not np.all(x == self.x) or self._value is None or self.jac is None:
     69     self.x = np.asarray(x).copy()
---> 70     fg = self.fun(x, *args)
     71     self.jac = fg[1]
     72     self._value = fg[0]

File /opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_linear_loss.py:200, in LinearModelLoss.loss_gradient(self, coef, X, y, sample_weight, l2_reg_strength, n_threads)
    198 loss += 0.5 * l2_reg_strength * (weights @ weights)
    199 grad = np.empty_like(coef, dtype=weights.dtype)
--> 200 grad[:n_features] = X.T @ grad_per_sample + l2_reg_strength * weights
    201 if self.fit_intercept:
    202     grad[-1] = grad_per_sample.sum()

KeyboardInterrupt: 